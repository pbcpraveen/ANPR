# -*- coding: utf-8 -*-
"""APNR_22MAR.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IEd4C50jsN4qTBEtDjhNEQr5WNNAf9QP
"""
import cv2
from keras.models import load_model
import numpy as np
import operator
from keras.models import Sequential
from keras.layers import Convolution2D, MaxPooling2D
from keras.layers import Flatten, Dense
def preprocess(ROI):
    # Converting the image to the grayscale
    gray1 = cv2.cvtColor(ROI,cv2.COLOR_BGR2GRAY)
    
    
    # to remove the unwnated noises in the surroundings the image is blurred with a kernel size of 5x5 
    bright=np.ones((3,3),dtype='uint8')*(1/9) #kernel matrix
    gray=cv2.filter2D(gray1,-1,bright)
    
    # Finding Canny edges
    #canny edge algorithm will plot all the possible contours in the pre processed image
    edged = cv2.Canny(gray, 5, 100)
    
    # to remove unwanted minor edges morphological operation is done on the cannied image.
    kernel = np.ones((3,3), np.uint8)
    morph = cv2.morphologyEx(edged, cv2.MORPH_CLOSE, kernel)
    # MORPH_OPEN : dilate and erode
    # MORPH_CLOSE: Erode and Dilate
    return morph

def extract_ROI(image1):
    height_orginal,width_orginal=image1.shape[:2]
    #we resize the image to a standard size thus we can make sure that 
    #the plate is always positioned perfectly
    img_scaled = cv2.resize(image1, (1300, 500), interpolation = cv2.INTER_CUBIC)
    height,width=img_scaled.shape[:2]
    #cropping the ROI from the image
    #we assume that the plate will appear only on the bottom part of the image
    start_row,end_row = int(4*height/7),int(height)
    start_coloumn,end_coloumn =int(2*width/10) , int(9*width/10)
    ROI=img_scaled[start_row:end_row,start_coloumn:end_coloumn]
    roi_height,roi_width= ROI.shape[:2]
    scaling_factor_height=height_orginal/height
    scaling_factor_width= width_orginal/width
    #computing the orginal dimensions of ROI in the given image
    h=scaling_factor_height*roi_height
    w=scaling_factor_width*roi_width
    ROI=cv2.resize(ROI,(int(w)*2,int(h)*2),interpolation=cv2.INTER_CUBIC)
    return ROI

def create_model_alphabets():
    model = Sequential()
    model.add(Convolution2D(16, 5, 5, activation='relu', input_shape=(28,28, 3)))
    model.add(MaxPooling2D(2, 2))

    model.add(Convolution2D(32, 5, 5, activation='relu'))
    model.add(MaxPooling2D(2, 2))

    model.add(Flatten())
    model.add(Dense(1000, activation='relu'))

    model.add(Dense(26, activation='softmax'))
    return model

def create_model_numbers():
    model = Sequential()
    model.add(Convolution2D(16, 5, 5, activation='relu', input_shape=(28,28, 3)))
    model.add(MaxPooling2D(2, 2))

    model.add(Convolution2D(32, 5, 5, activation='relu'))
    model.add(MaxPooling2D(2, 2))

    model.add(Flatten())
    model.add(Dense(1000, activation='relu'))

    model.add(Dense(10, activation='softmax'))
    return model
def get_model_image(img):
    next2 = cv2.resize(img, (28,28))
    ret, gray1 = cv2.threshold(next2,254,255,cv2.THRESH_BINARY)
    img = np.zeros((28,28,3),dtype = np.uint8)
    h = np.ones((48,48),dtype = np.uint8)*255
    h[10:38,10:38] = gray1
    gray1 = cv2.resize(h, (28,28))
    img[:,:,0] = gray1
    img[:,:,1] = gray1
    img[:,:,2] = gray1
    ar = img.reshape((28,28,3))
    cv2.imshow('tets',img)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    ar = np.expand_dims(ar, axis=0)
    return ar

classifier = load_model('plate_model.h5')

number = create_model_numbers()
number.load_weights('plate_numbers.h5')

alphabet = create_model_alphabets()
alphabet.load_weights('alpha2.h5')

image1 = cv2.imread('truck2.jpg')

ROI = extract_ROI(image1)

thresh = preprocess(ROI)


contours,hirarchy = cv2.findContours(thresh, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)

plate=contours[0]
#To find number of contours detected
print("Number of Contours found = " + str(len(contours)))
test=ROI.copy()
selected=[]
plate1=None
flag=0
error =0.6
aspect = 4.1667
rmin = aspect - aspect * error
rmax = aspect + aspect * error
minarea = 15 *15*aspect
maxarea = 125 * 125 * aspect
from keras.preprocessing import image
for e,k in enumerate(contours):
    x,y,w,h=cv2.boundingRect(k)
    img=ROI[y:y+h,x:x+w]
    img1 = img.copy()
    #cv2_imshow(img)
    area = h*w
    r=w/h
    if(r<1):
        r=h/w
    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)
    
    canny_img=cv2.Canny(img,20,150)
    ret,thresh_img = cv2.threshold(canny_img, 127, 255, cv2.THRESH_TOZERO)
    c,hi = cv2.findContours(canny_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
    if((minarea<area and maxarea>area) and (rmin<r and rmax>r) and len(c)>20 and w>h):
      test_image = img1
      test_image=cv2.resize(test_image,(30,100),interpolation=cv2.INTER_CUBIC)
      test_image = image.img_to_array(test_image)
      test_image = np.expand_dims(test_image, axis = 0)
      result = classifier.predict(test_image)
      if (result[0][0] ==1) :
        x1,y1,w1,h1=cv2.boundingRect(k)    
        plate1=ROI[y1:y1+int(h1),x1:x1+int(w1)]
        cv2.imshow('pre',plate1)
        cv2.waitKey(0)
        print("plate is found")
        flag=1
        
if(flag==0):
    print("plate contour was not found")


img = cv2.cvtColor(plate1,cv2.COLOR_BGR2GRAY)
img = cv2.resize(img,(5*len(img[0]),5*len(img)),interpolation = cv2.INTER_CUBIC)
plate=img.copy()
r,plate  = cv2.threshold(plate,int(plate1.flatten().mean()),255,cv2.THRESH_BINARY)
backup=plate.copy()

contours,hi = cv2.findContours(plate.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
chars = dict()
for c in contours:        
    x,y,w,h=cv2.boundingRect(c)
    #cv2.rectangle(backup,(x,y),(x+w,y+h),(60,255,40),1)
    char_image=plate[y:y+h,x:x+w]
    
    cv2.destroyAllWindows()
    if(w*h>0 and w>10 and h>152 and w<300):
        char_image=plate[y:y+h,x:x+w]
        
        canny_img=cv2.Canny(char_image,30,200)
        c,hi = cv2.findContours(canny_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
        if(len(c)>=1 ):
            chars[x] = char_image
            cv2.rectangle(backup,(x,y),(x+w,y+h),(60,255,40),1)

chars = sorted(chars.items(), key=operator.itemgetter(0))


def predic_plate(chars):
    s = ''
    global alphabet
    global numbers
    prediction = alphabet.predict(get_model_image(chars[0][1]))[0].tolist()
    ans = prediction.index(max(prediction))
    s+=chr(ans+65)
    print(s)
    prediction = alphabet.predict(get_model_image(chars[1][1]))[0].tolist()
    ans = prediction.index(max(prediction))
    s+=chr(ans+65)
    print(s)
    prediction = number.predict(get_model_image(chars[2][1]))[0].tolist()
    ans = prediction.index(max(prediction))
    s+=str(ans)
    print(s)
    prediction = number.predict(get_model_image(chars[3][1]))[0].tolist()
    ans = prediction.index(max(prediction))
    s+=str(ans)
    print(s)
    prediction = alphabet.predict(get_model_image(chars[4][1]))[0].tolist()
    ans = prediction.index(max(prediction))
    s+=chr(ans+65)
    print(s)
    prediction = alphabet.predict(get_model_image(chars[5][1]))[0].tolist()
    ans = prediction.index(max(prediction))
    s+=chr(ans+65)
    print(s)
    prediction = number.predict(get_model_image(chars[6][1]))[0].tolist()
    ans = prediction.index(max(prediction))
    s+=str(ans)
    print(s)
    prediction = number.predict(get_model_image(chars[7][1]))[0].tolist()
    ans = prediction.index(max(prediction))
    s+=str(ans)
    print(s)
    prediction = number.predict(get_model_image(chars[8][1]))[0].tolist()
    ans = prediction.index(max(prediction))
    s+=str(ans)
    print(s)
    prediction = number.predict(get_model_image(chars[9][1]))[0].tolist()
    ans = prediction.index(max(prediction))
    s+=str(ans)
    return s
print(predic_plate(chars))  
cv2.imshow('pre',cv2.resize(plate1,(len(plate1[0])*4,len(plate1)*4)))
cv2.waitKey(0)
cv2.destroyAllWindows()
cv2.imshow('pre2',cv2.resize(plate1,(len(plate1[0])*4,len(plate1)*4)))
cv2.imshow('pre',t)
cv2.imshow('pre1',t1)
cv2.waitKey(0)
cv2.destroyAllWindows()
#----------------------------------------------------------------------------------------


contours,hi = cv2.findContours(t1.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
chars = dict()
for c in contours:        
    x,y,w,h=cv2.boundingRect(c)
    #cv2.rectangle(backup,(x,y),(x+w,y+h),(60,255,40),1)
    char_image=plate[y:y+h,x:x+w]
    cv2.imshow('img',char_image)
    cv2.waitKey(0)
    cv2.destroyAllWindows()
    if(w*h>0 and w>10 and h>152 and w<500):
        char_image=plate[y:y+h,x:x+w]
        cv2.imshow('img2',char_image)
        cv2.waitKey(0)
        canny_img=cv2.Canny(char_image,30,200)
        c,hi = cv2.findContours(canny_img, cv2.RETR_LIST, cv2.CHAIN_APPROX_NONE)
        if(len(c)>=1 ):
            chars[x] = char_image
            cv2.rectangle(backup,(x,y),(x+w,y+h),(60,255,40),1)
cv2.destroyAllWindows()
chars = sorted(chars.items(), key=operator.itemgetter(0))